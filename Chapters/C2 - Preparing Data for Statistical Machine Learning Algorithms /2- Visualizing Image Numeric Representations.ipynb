{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Representing Images as Matrices**\n","\n","### **Introduction and Objectives**\n","\n","In this lab, we will explore how images are represented numerically in a machine learning pipeline. By the end of this lab, you will:\n","- Understand how to load images as NumPy arrays.\n","- Learn how color channels (RGB) translate to 3D arrays.\n","- Perform simple manipulations (e.g., resizing, reshaping, normalizing).\n","- Prepare images as model inputs in a way that is acceptable to typical ML frameworks.\n"],"metadata":{"id":"aUhEscQvtBPC"}},{"cell_type":"markdown","source":["## üìö **Imports and Libraries**\n","\n","**Why these libraries?**\n","- **OpenCV (cv2)**: A powerful library for reading, writing, and manipulating images and videos. We will use its functions to load images, resize them, convert them to grayscale, and apply a threshold.\n","\n","### üîó **References:**\n","- [OpenCV Documentation](https://docs.opencv.org/master/)\n"],"metadata":{"id":"5kh_RsNAvDl8"}},{"cell_type":"markdown","source":["## **1Ô∏è‚É£ Load Grayscale and Apply Threshold**"],"metadata":{"id":"DU8jC2JdhYPj"}},{"cell_type":"code","source":["!git clone https://github.com/AmmarMohanna/EECE490 images"],"metadata":{"id":"7Dwfw887vhoo","executionInfo":{"status":"ok","timestamp":1740224883891,"user_tz":-120,"elapsed":3555,"user":{"displayName":"Ammar Mohanna","userId":"01193371947507864089"}},"outputId":"421a5f8e-b17a-4fa8-8f47-39e092381046","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'images'...\n","remote: Enumerating objects: 65, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (58/58), done.\u001b[K\n","remote: Total 65 (delta 2), reused 64 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (65/65), 27.12 MiB | 12.41 MiB/s, done.\n","Resolving deltas: 100% (2/2), done.\n"]}]},{"cell_type":"code","source":["import cv2\n","\n","# We will demonstrate loading an image in grayscale mode, resizing it, and applying a threshold.\n","image = cv2.imread('/content/images/data_for_labs/chapter_2/dino.png', cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n","image = cv2.resize(image, (15, 15))  # Resize to 15x15 for simplicity\n","\n","# Apply a binary threshold\n","# Any pixel value above 100 becomes 1, below 100 becomes 0.\n","_, binary_image = cv2.threshold(image, 100, 1, cv2.THRESH_BINARY)\n","\n","# Display the resulting binary image array\n","binary_image\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"d1pBfH3w7DXe","executionInfo":{"status":"ok","timestamp":1740224884270,"user_tz":-120,"elapsed":377,"user":{"displayName":"Ammar Mohanna","userId":"01193371947507864089"}},"outputId":"42c786d5-990c-4360-b3cf-83364f14df97"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-4d977df5-62b2-4324-b93f-041530afa81b\" class=\"ndarray_repr\"><pre>ndarray (15, 15) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAPCAAAAAAevcqWAAAAPUlEQVR4nH2PSQoAIAzEJsX/f3k8uOAo6KkhoVhQvEpUW4Ml8fofk8z2lh29d1SZDz7+WNNB9KSX10qu+zrfLgcjyA8T4AAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-4d977df5-62b2-4324-b93f-041530afa81b button').onclick = (e) => {\n","        document.querySelector('#id-4d977df5-62b2-4324-b93f-041530afa81b').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-4d977df5-62b2-4324-b93f-041530afa81b button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["**Explanation:**\n","\n","1. **`cv2.imread('/content/dino.png', cv2.IMREAD_GRAYSCALE)`** loads the specified image file in grayscale mode.  \n","2. **`cv2.resize(image, (15, 15))`** resizes the image to a 15√ó15 pixel dimension.  \n","3. **`cv2.threshold(image, 100, 1, cv2.THRESH_BINARY)`** applies a binary threshold:  \n","   - Threshold value = 100  \n","   - Values above 100 become 1  \n","   - Values below 100 become 0  \n","\n","The output, `binary_image`, is a 2D array (matrix) of 0s and 1s. Each cell in the matrix corresponds to a pixel in the thresholded image.\n"],"metadata":{"id":"AR5NAGeexltX"}},{"cell_type":"markdown","source":["## **2Ô∏è‚É£ Load and Display Grayscale**"],"metadata":{"id":"HySx5pKSh3nb"}},{"cell_type":"code","source":["# Load and display the grayscale image as a matrix\n","image = cv2.imread('/content/images/data_for_labs/chapter_2/dino.png', cv2.IMREAD_GRAYSCALE)\n","image = cv2.resize(image, (15, 15))\n","\n","# Display the grayscale image array\n","image"],"metadata":{"id":"iUCzdMAU9p6L","executionInfo":{"status":"ok","timestamp":1740224945607,"user_tz":-120,"elapsed":29,"user":{"displayName":"Ammar Mohanna","userId":"01193371947507864089"}},"colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"128b19ad-23d4-4729-e5fc-515bb4c1370d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254,\n","        254, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   2,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,  87, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 253,   0,   0, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255,   0, 255,   0,   0,   0,   1, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 254, 254,   0,   0,   0,   0,   0,  25, 254, 254, 254,\n","        254, 255],\n","       [255, 255, 255, 255,   0,   0,   0,   0,   0, 187, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255,   0,   0,   0,   0, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 251,   0, 253, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 148, 255, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255,   0, 255,   0, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n","        255, 255]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-660702c5-4ae7-46e7-8dfd-a1f6a5985946\" class=\"ndarray_repr\"><pre>ndarray (15, 15) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAPCAAAAAAevcqWAAAAWElEQVR4nFWOyw2AMAxDn9sOwWYsxjaMhqg5pEGpL4kT+SOzYUC9SMn6BEPLz4zR2FH4aSD1s4fvAJAFKnkCDgPCdkhu23boRdYK/4fXNW9cmbvy5H/Z+32heyDIt7tJAgAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254, 254,\n","        254, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   2,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,   0,   0, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255,   0,   0,  87, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 253,   0,   0, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255,   0, 255,   0,   0,   0,   1, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 254, 254,   0,   0,   0,   0,   0,  25, 254, 254, 254,\n","        254, 255],\n","       [255, 255, 255, 255,   0,   0,   0,   0,   0, 187, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255,   0,   0,   0,   0, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 251,   0, 253, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 148, 255, 255, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255,   0, 255,   0, 255, 255, 255, 255,\n","        255, 255],\n","       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n","        255, 255]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-660702c5-4ae7-46e7-8dfd-a1f6a5985946 button').onclick = (e) => {\n","        document.querySelector('#id-660702c5-4ae7-46e7-8dfd-a1f6a5985946').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-660702c5-4ae7-46e7-8dfd-a1f6a5985946 button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**Explanation:**\n","\n","In this cell, we:\n","- Reload the original image (`/content/dino.png`) in **grayscale**.\n","- Resize the image to a **15√ó15** pixel dimension.\n","- Simply display the **NumPy array** of grayscale pixel values (ranging from 0 to 255).\n","\n","You can see the shape `(15, 15)` if you print `image.shape`. Every element corresponds to a single pixel's intensity.\n","\n","**Example**:\n","```python\n","print(\"Image Shape:\", image.shape)\n","print(\"A pixel example (row=0, col=0):\", image[0, 0])\n"],"metadata":{"id":"6HNFaR-GyDQT"}},{"cell_type":"markdown","source":["## **3Ô∏è‚É£ Load and Display Color Image**"],"metadata":{"id":"AupzHnwtiODw"}},{"cell_type":"code","source":["# Load and display the color image as a matrix\n","image = cv2.imread('/content/images/data_for_labs/chapter_2/dino.png')  # Load the image in color\n","image = cv2.resize(image, (15, 15))     # Resize to 15x15\n","\n","# Display the color image array\n","image"],"metadata":{"id":"n17q0FE1_g0Q","executionInfo":{"status":"ok","timestamp":1737619765426,"user_tz":-120,"elapsed":311,"user":{"displayName":"Ammar Mohanna","userId":"01193371947507864089"}},"colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"e8736846-85d8-46b2-d65a-5c55aea9d3c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  2,   2,   2],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [ 87,  87,  87],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [253, 253, 253],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  1,   1,   1],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [ 25,  25,  25],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [187, 187, 187],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [251, 251, 251],\n","        [  0,   0,   0],\n","        [253, 253, 253],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [148, 148, 148],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-a2fa176a-e059-4014-90ad-4d1a2507da0a\" class=\"ndarray_repr\"><pre>ndarray (15, 15, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAPCAIAAAC0tAIdAAAAgUlEQVR4nJVS0Q0FIQijwhBu5mJu42hGeB+XGI7D3L3+GEJp2kaYGX2GXM+XGwA48ZhZVYNWOSltqseRneKF3VrzVnPfqsrM9EgvfrhCA9hjUIkNekat9WYDIHMISmMMuyP69trP+9jJnJOI1lpp+sgWkd57KXmzSYO7mWT11x/8AT92Yh7ndjEAAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  2,   2,   2],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [ 87,  87,  87],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [253, 253, 253],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  1,   1,   1],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [ 25,  25,  25],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [254, 254, 254],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [187, 187, 187],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [251, 251, 251],\n","        [  0,   0,   0],\n","        [253, 253, 253],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [148, 148, 148],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [  0,   0,   0],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]],\n","\n","       [[255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255],\n","        [255, 255, 255]]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-a2fa176a-e059-4014-90ad-4d1a2507da0a button').onclick = (e) => {\n","        document.querySelector('#id-a2fa176a-e059-4014-90ad-4d1a2507da0a').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-a2fa176a-e059-4014-90ad-4d1a2507da0a button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["**Explanation:**\n","\n","1. **`cv2.imread('/content/images/data_for_labs/chapter_2/dino.png')`** defaults to loading images in **BGR** (Blue, Green, Red) format in OpenCV. Unlike the grayscale image, this now has 3 channels.  \n","2. **`cv2.resize(image, (15, 15))`** again resizes to 15√ó15.  \n","3. Printing the array displays a shape of **(15, 15, 3)**, indicating **height = 15**, **width = 15**, and **3 color channels**.\n","\n","For color images, each pixel is represented by three intensity values, one for each channel (B, G, R).\n"],"metadata":{"id":"bM_QrLOGyVas"}},{"cell_type":"markdown","source":["## **Key Takeaways**\n","\n","- **Images as Arrays**: A grayscale image can be viewed as a 2D array, while a color image generally has three channels (e.g., BGR or RGB).\n","- **Resizing**: Changing the height and width can be crucial for memory constraints and for standardizing input sizes in ML.\n","- **Thresholding**: Binary thresholding transforms each pixel into a 0 or 1, often used for segmentation or turning images into a simpler form.\n","- **OpenCV Default**: By default, OpenCV reads images in the BGR channel ordering, while other libraries (like Matplotlib) might expect RGB.\n"],"metadata":{"id":"zN-AFMrjye_k"}},{"cell_type":"markdown","source":["## **Reflection Questions**\n","\n","1. Why might we want to resize an image before passing it to a machine learning model?\n","2. What are some downstream computer vision tasks that benefit from binary thresholding?\n","3. How do the shapes of grayscale vs. color images differ numerically?\n"],"metadata":{"id":"82KFtmLhfzv6"}},{"cell_type":"markdown","source":["# **OPTIONAL: Basic Image Normalization**\n","\n","When working with images in Machine Learning, we often normalize or scale pixel values. This step can help many algorithms and neural networks train more effectively.\n","\n","For instance, **min-max normalization** maps pixel values from the range [0, 255] to [0, 1], making the image data more suitable for models that expect small input values or that are sensitive to large variations.\n","\n","**Why Normalize?**\n","- It ensures consistent data ranges (e.g., [0, 1]) across different images.\n","- Some machine learning models (like neural networks) converge faster when inputs are normalized.\n","- Normalization can reduce the impact of extreme pixel values (e.g., very bright or dark).\n","\n","Below is a quick demonstration of how to normalize a grayscale image to a [0, 1] range.\n"],"metadata":{"id":"hdYE6NVXmZzF"}},{"cell_type":"code","source":["# OPTIONAL CODE EXAMPLE: Basic Image Normalization\n","\n","import cv2\n","import numpy as np\n","\n","# 1) Load the image in grayscale\n","image = cv2.imread('/content/images/data_for_labs/chapter_2/dino.png', cv2.IMREAD_GRAYSCALE)\n","\n","# 2) Convert the image to float type for precise calculations\n","image_float = image.astype(np.float32)\n","\n","# 3) Compute min and max pixel values\n","min_val = image_float.min()\n","max_val = image_float.max()\n","\n","# 4) Perform min-max normalization to the range [0, 1]\n","normalized_image = (image_float - min_val) / (max_val - min_val)\n","\n","print(\"Before normalization:\")\n","print(\"  Data type:\", image.dtype)\n","print(\"  Pixel range:\", image.min(), \"to\", image.max())\n","\n","print(\"\\nAfter normalization:\")\n","print(\"  Data type:\", normalized_image.dtype)  # Should be float\n","print(\"  Pixel range:\", normalized_image.min(), \"to\", normalized_image.max())\n"],"metadata":{"id":"HpuQmSxfmkxp","executionInfo":{"status":"ok","timestamp":1737365636403,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ammar Mohanna","userId":"01193371947507864089"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03ccdadd-d784-4295-9d2d-fa264ff8faf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Before normalization:\n","  Data type: uint8\n","  Pixel range: 0 to 255\n","\n","After normalization:\n","  Data type: float32\n","  Pixel range: 0.0 to 1.0\n"]}]},{"cell_type":"markdown","source":["**Explanation:**\n","\n","1. We load the image in grayscale (cv2.IMREAD_GRAYSCALE).\n","2. We convert its data type to float32 for precision (originally it‚Äôs uint8).\n","3. We apply the standard formula for min-max normalization:\n","\n","$$\\text{normalized_pixel} = \\frac{\\text{pixel} - \\text{min_val}}{\\text{max_val} - \\text{min_val}}$$\n","\n","4. After normalization, the pixel range should be [0.0, 1.0].\n"],"metadata":{"id":"hFzppGwFpAGF"}},{"cell_type":"markdown","source":["###**TODO: Practice Normalizing an Image**\n","\n","Try one or more of the following mini-tasks to solidify your understanding:\n","\n","1. **Custom Normalization Range**  \n","   - Modify the code above so the image is scaled to the range `[0, 255]` again (effectively re-scaling after normalization).  \n","   - *Hint:* You might multiply the normalized image by 255 and convert it back to `uint8`.\n","\n","2. **Color Image Normalization**  \n","   - Load the **color** image (BGR) instead of grayscale.  \n","   - Convert it to a float type and normalize each channel to [0, 1].  \n","   - Print or observe the pixel range for each channel.\n","\n","3. **Compare Histograms** (Optional)  \n","   - Use `cv2.calcHist()` or any other method to compute the histogram of the original grayscale image versus the normalized one.  \n","   - See how normalization alters the distribution of pixel values.\n","   \n","Document your observations in a new Markdown cell. If you feel comfortable, show a quick visualization of the normalized image using `matplotlib` to confirm that the image still ‚Äúlooks‚Äù the same, just with different numerical values.\n"],"metadata":{"id":"A9DZvXalmly_"}},{"cell_type":"code","source":["#TODO HERE"],"metadata":{"id":"gJA2jpmFmztV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üîó **Additional Resources**\n","\n","- **OpenCV Documentation:** [https://docs.opencv.org/master/](https://docs.opencv.org/master/)\n","- **NumPy Documentation (array manipulations):** [https://numpy.org/doc/](https://numpy.org/doc/)\n","- **Stanford CS231n (Image Data):** [http://cs231n.github.io/python-numpy-tutorial/#images](http://cs231n.github.io/python-numpy-tutorial/#images)\n","- **OpenCV Basic Image Operations:** [https://docs.opencv.org/master/dc/d71/tutorial_py_emi.html](https://docs.opencv.org/master/dc/d71/tutorial_py_emi.html)\n","\n","\n","---\n","\n","# üìö **Further Suggested Readings**\n","\n","- **Pillow (PIL) Documentation:** [https://pillow.readthedocs.io/en/stable/](https://pillow.readthedocs.io/en/stable/)  \n","  Useful for opening and processing images in Python without OpenCV.\n","\n","- **scikit-image Documentation:** [https://scikit-image.org/docs/stable/](https://scikit-image.org/docs/stable/)  \n","  A Python library for advanced image processing tasks such as edge detection, filters, and morphological operations.\n","\n","- **Image Preprocessing Tips:**  \n","  Articles and tutorials on techniques like normalization, augmentation, and how these impact model performance:\n","  1. [How to Configure Image Data Augmentation When Training Deep Learning Neural Networks (Machine Learning Mastery)](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)  \n","  2. [Keras Image Preprocessing Layers (Official Keras Docs)](https://keras.io/api/preprocessing/image/)  \n","  3. [Data Augmentation | TensorFlow Core](https://www.tensorflow.org/tutorials/images/data_augmentation)  \n","  4. [CS231n: Normalization and BatchNorm](http://cs231n.github.io/neural-networks-2/#batchnorm)\n","\n","---\n","\n","# üîó **Kaggle Resources and Example Notebooks**\n","\n","- [**Image Processing Basics with OpenCV for Beginners**](https://www.kaggle.com/code/zeeshanlatif/image-processing-basics-with-opencv-for-beginners): A beginner-friendly notebook demonstrating fundamental OpenCV operations like reading images, color space conversions, and basic transformations.  \n","- [**Complete Guide to Image Processing with OpenCV**](https://www.kaggle.com/code/natigmamishov/complete-guide-to-image-processing-with-opencv): Covers advanced OpenCV techniques, including filtering, edge detection, and morphological transformations.  \n","- [**Learn OpenCV by Examples - with Python**](https://www.kaggle.com/code/bulentsiyah/learn-opencv-by-examples-with-python): Provides practical examples for tasks like image thresholding, contour detection, and histogram equalization using OpenCV and Python.  "],"metadata":{"id":"D8RRT5Y0gKW_"}}]}